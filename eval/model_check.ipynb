{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "925918fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eaaae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Projects\\36118 ANLP\\Assignment 2\\LLM\\LegalEase_NSW\\github_repo\\eval\\outputs\\llm_generation_and_evaluation_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fc9281b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            format_pass  bertscore_f1  flesch_kincaid_grade  \\\n",
      "model_name                                                                    \n",
      "claude-3-5-sonnet-20240620     0.297980      0.859115              6.549417   \n",
      "claude-3-opus-20240229         0.350962      0.859282              8.631613   \n",
      "gemini-2.5-flash               0.490385      0.869389              5.414282   \n",
      "gemini-2.5-pro                 0.418269      0.867278              5.904126   \n",
      "gpt-3.5-turbo                  0.500000      0.872966              8.573203   \n",
      "gpt-4-turbo                    0.500000      0.875456              8.852759   \n",
      "gpt-4o                         0.500000      0.870473              7.313176   \n",
      "\n",
      "                            latency_seconds  \n",
      "model_name                                   \n",
      "claude-3-5-sonnet-20240620         5.317576  \n",
      "claude-3-opus-20240229             7.548510  \n",
      "gemini-2.5-flash                  20.223798  \n",
      "gemini-2.5-pro                    19.306779  \n",
      "gpt-3.5-turbo                      2.279471  \n",
      "gpt-4-turbo                        6.066587  \n",
      "gpt-4o                             4.191538  \n",
      "                    format_pass  bertscore_f1  flesch_kincaid_grade\n",
      "prompt_name                                                        \n",
      "Default                0.900000      0.859147              9.199503\n",
      "Engaging               0.000000      0.894887             10.566466\n",
      "Explain like I'm 5     0.000000      0.869937              2.267520\n",
      "With example           0.853591      0.847054              7.277364\n"
     ]
    }
   ],
   "source": [
    "# Remove API failures\n",
    "df_success = df[df['generated_summary'] != 'API_CALL_FAILED']\n",
    "\n",
    "# Model-level stats (averaged across ALL prompts)\n",
    "model_stats = df_success.groupby('model_name').agg({\n",
    "    'format_pass': 'mean',\n",
    "    'bertscore_f1': 'mean',\n",
    "    'flesch_kincaid_grade': 'mean',\n",
    "    'latency_seconds': 'mean'\n",
    "})\n",
    "\n",
    "print(model_stats)\n",
    "\n",
    "# Prompt-level stats (averaged across ALL models)\n",
    "prompt_stats = df_success.groupby('prompt_name').agg({\n",
    "    'format_pass': 'mean',\n",
    "    'bertscore_f1': 'mean',\n",
    "    'flesch_kincaid_grade': 'mean'\n",
    "})\n",
    "\n",
    "print(prompt_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bff5bd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE SIZES BY PROMPT\n",
      "                        mean  count  sum\n",
      "prompt_name                             \n",
      "Default             0.900000    360  324\n",
      "Engaging            0.000000    362    0\n",
      "Explain like I'm 5  0.000000    362    0\n",
      "With example        0.853591    362  309\n",
      "SAMPLE SIZES BY MODEL\n",
      "                                mean  count  sum\n",
      "model_name                                      \n",
      "claude-3-5-sonnet-20240620  0.297980    198   59\n",
      "claude-3-opus-20240229      0.350962    208   73\n",
      "gemini-2.5-flash            0.490385    208  102\n",
      "gemini-2.5-pro              0.418269    208   87\n",
      "gpt-3.5-turbo               0.500000    208  104\n",
      "gpt-4-turbo                 0.500000    208  104\n",
      "gpt-4o                      0.500000    208  104\n",
      "FULL MODEL×PROMPT BREAKDOWN\n",
      "                                                   mean  count  sum\n",
      "model_name                 prompt_name                             \n",
      "gemini-2.5-flash           With example        1.000000     52   52\n",
      "gpt-3.5-turbo              With example        1.000000     52   52\n",
      "                           Default             1.000000     52   52\n",
      "gemini-2.5-pro             With example        1.000000     52   52\n",
      "gpt-4-turbo                Default             1.000000     52   52\n",
      "                           With example        1.000000     52   52\n",
      "gpt-4o                     With example        1.000000     52   52\n",
      "                           Default             1.000000     52   52\n",
      "gemini-2.5-flash           Default             0.961538     52   50\n",
      "claude-3-5-sonnet-20240620 Default             0.937500     48   45\n",
      "claude-3-opus-20240229     Default             0.730769     52   38\n",
      "                           With example        0.673077     52   35\n",
      "gemini-2.5-pro             Default             0.673077     52   35\n",
      "claude-3-5-sonnet-20240620 With example        0.280000     50   14\n",
      "gemini-2.5-flash           Explain like I'm 5  0.000000     52    0\n",
      "                           Engaging            0.000000     52    0\n",
      "claude-3-5-sonnet-20240620 Engaging            0.000000     50    0\n",
      "                           Explain like I'm 5  0.000000     50    0\n",
      "claude-3-opus-20240229     Engaging            0.000000     52    0\n",
      "                           Explain like I'm 5  0.000000     52    0\n",
      "gpt-3.5-turbo              Explain like I'm 5  0.000000     52    0\n",
      "                           Engaging            0.000000     52    0\n",
      "gemini-2.5-pro             Engaging            0.000000     52    0\n",
      "                           Explain like I'm 5  0.000000     52    0\n",
      "gpt-4-turbo                Explain like I'm 5  0.000000     52    0\n",
      "                           Engaging            0.000000     52    0\n",
      "gpt-4o                     Engaging            0.000000     52    0\n",
      "                           Explain like I'm 5  0.000000     52    0\n"
     ]
    }
   ],
   "source": [
    "# Check sample sizes per group\n",
    "print(\"SAMPLE SIZES BY PROMPT\")\n",
    "print(df_success.groupby('prompt_name')['format_pass'].agg(['mean', 'count', 'sum']))\n",
    "\n",
    "print(\"SAMPLE SIZES BY MODEL\")\n",
    "print(df_success.groupby('model_name')['format_pass'].agg(['mean', 'count', 'sum']))\n",
    "\n",
    "print(\"FULL MODEL×PROMPT BREAKDOWN\")\n",
    "combo_detail = df_success.groupby(['model_name', 'prompt_name'])['format_pass'].agg(['mean', 'count', 'sum'])\n",
    "print(combo_detail.sort_values('mean', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "747b38c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               format_pass\n",
      "model_name       prompt_name              \n",
      "gemini-2.5-flash With example          1.0\n"
     ]
    }
   ],
   "source": [
    "# Best model×prompt combination\n",
    "best_combo = df_success.groupby(['model_name', 'prompt_name']).agg({\n",
    "    'format_pass': 'mean'\n",
    "}).sort_values('format_pass', ascending=False).head(1)\n",
    "\n",
    "print(best_combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89b3fe29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall model averages (across all 4 prompts):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Format Compliance</th>\n",
       "      <th>BERTScore F1</th>\n",
       "      <th>Readability (Grade)</th>\n",
       "      <th>Latency (seconds)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>claude-3-5-sonnet-20240620</th>\n",
       "      <td>0.298</td>\n",
       "      <td>0.859</td>\n",
       "      <td>6.549</td>\n",
       "      <td>5.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-opus-20240229</th>\n",
       "      <td>0.351</td>\n",
       "      <td>0.859</td>\n",
       "      <td>8.632</td>\n",
       "      <td>7.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2.5-flash</th>\n",
       "      <td>0.490</td>\n",
       "      <td>0.869</td>\n",
       "      <td>5.414</td>\n",
       "      <td>20.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2.5-pro</th>\n",
       "      <td>0.418</td>\n",
       "      <td>0.867</td>\n",
       "      <td>5.904</td>\n",
       "      <td>19.307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.873</td>\n",
       "      <td>8.573</td>\n",
       "      <td>2.279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.875</td>\n",
       "      <td>8.853</td>\n",
       "      <td>6.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.870</td>\n",
       "      <td>7.313</td>\n",
       "      <td>4.192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Format Compliance  BERTScore F1  \\\n",
       "model_name                                                    \n",
       "claude-3-5-sonnet-20240620              0.298         0.859   \n",
       "claude-3-opus-20240229                  0.351         0.859   \n",
       "gemini-2.5-flash                        0.490         0.869   \n",
       "gemini-2.5-pro                          0.418         0.867   \n",
       "gpt-3.5-turbo                           0.500         0.873   \n",
       "gpt-4-turbo                             0.500         0.875   \n",
       "gpt-4o                                  0.500         0.870   \n",
       "\n",
       "                            Readability (Grade)  Latency (seconds)  \n",
       "model_name                                                          \n",
       "claude-3-5-sonnet-20240620                6.549              5.318  \n",
       "claude-3-opus-20240229                    8.632              7.549  \n",
       "gemini-2.5-flash                          5.414             20.224  \n",
       "gemini-2.5-pro                            5.904             19.307  \n",
       "gpt-3.5-turbo                             8.573              2.279  \n",
       "gpt-4-turbo                               8.853              6.067  \n",
       "gpt-4o                                    7.313              4.192  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL PERFORMANCE ON STRUCTURED PROMPTS ONLY (Default + With example):\n",
      "Structured prompt performance by model:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Format Compliance</th>\n",
       "      <th>Passed Count</th>\n",
       "      <th>Total Cases</th>\n",
       "      <th>BERTScore F1</th>\n",
       "      <th>Readability (Grade)</th>\n",
       "      <th>Latency (seconds)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>claude-3-5-sonnet-20240620</th>\n",
       "      <td>0.602</td>\n",
       "      <td>59</td>\n",
       "      <td>98</td>\n",
       "      <td>0.847</td>\n",
       "      <td>8.281</td>\n",
       "      <td>5.207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-opus-20240229</th>\n",
       "      <td>0.702</td>\n",
       "      <td>73</td>\n",
       "      <td>104</td>\n",
       "      <td>0.851</td>\n",
       "      <td>9.495</td>\n",
       "      <td>8.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2.5-flash</th>\n",
       "      <td>0.981</td>\n",
       "      <td>102</td>\n",
       "      <td>104</td>\n",
       "      <td>0.855</td>\n",
       "      <td>6.300</td>\n",
       "      <td>22.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2.5-pro</th>\n",
       "      <td>0.837</td>\n",
       "      <td>87</td>\n",
       "      <td>104</td>\n",
       "      <td>0.861</td>\n",
       "      <td>7.044</td>\n",
       "      <td>19.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo</th>\n",
       "      <td>1.000</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>0.850</td>\n",
       "      <td>8.478</td>\n",
       "      <td>2.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>1.000</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>0.855</td>\n",
       "      <td>9.672</td>\n",
       "      <td>7.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <td>1.000</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>0.852</td>\n",
       "      <td>8.384</td>\n",
       "      <td>4.793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Format Compliance  Passed Count  Total Cases  \\\n",
       "model_name                                                                 \n",
       "claude-3-5-sonnet-20240620              0.602            59           98   \n",
       "claude-3-opus-20240229                  0.702            73          104   \n",
       "gemini-2.5-flash                        0.981           102          104   \n",
       "gemini-2.5-pro                          0.837            87          104   \n",
       "gpt-3.5-turbo                           1.000           104          104   \n",
       "gpt-4-turbo                             1.000           104          104   \n",
       "gpt-4o                                  1.000           104          104   \n",
       "\n",
       "                            BERTScore F1  Readability (Grade)  \\\n",
       "model_name                                                      \n",
       "claude-3-5-sonnet-20240620         0.847                8.281   \n",
       "claude-3-opus-20240229             0.851                9.495   \n",
       "gemini-2.5-flash                   0.855                6.300   \n",
       "gemini-2.5-pro                     0.861                7.044   \n",
       "gpt-3.5-turbo                      0.850                8.478   \n",
       "gpt-4-turbo                        0.855                9.672   \n",
       "gpt-4o                             0.852                8.384   \n",
       "\n",
       "                            Latency (seconds)  \n",
       "model_name                                     \n",
       "claude-3-5-sonnet-20240620              5.207  \n",
       "claude-3-opus-20240229                  8.838  \n",
       "gemini-2.5-flash                       22.705  \n",
       "gemini-2.5-pro                         19.522  \n",
       "gpt-3.5-turbo                           2.718  \n",
       "gpt-4-turbo                             7.456  \n",
       "gpt-4o                                  4.793  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETAILED MODEL×PROMPT BREAKDOWN (structured prompts only):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Format Compliance</th>\n",
       "      <th>Passed</th>\n",
       "      <th>Total</th>\n",
       "      <th>BERTScore F1</th>\n",
       "      <th>Readability</th>\n",
       "      <th>Latency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gemini-2.5-flash</th>\n",
       "      <th>With example</th>\n",
       "      <td>1.000</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.846</td>\n",
       "      <td>5.221</td>\n",
       "      <td>22.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <th>Default</th>\n",
       "      <td>1.000</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.856</td>\n",
       "      <td>9.483</td>\n",
       "      <td>4.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <th>Default</th>\n",
       "      <td>1.000</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.859</td>\n",
       "      <td>10.993</td>\n",
       "      <td>8.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">gpt-3.5-turbo</th>\n",
       "      <th>With example</th>\n",
       "      <td>1.000</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.847</td>\n",
       "      <td>7.867</td>\n",
       "      <td>2.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Default</th>\n",
       "      <td>1.000</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.853</td>\n",
       "      <td>9.089</td>\n",
       "      <td>2.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2.5-pro</th>\n",
       "      <th>With example</th>\n",
       "      <td>1.000</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.853</td>\n",
       "      <td>6.146</td>\n",
       "      <td>20.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <th>With example</th>\n",
       "      <td>1.000</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.849</td>\n",
       "      <td>7.285</td>\n",
       "      <td>4.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <th>With example</th>\n",
       "      <td>1.000</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.850</td>\n",
       "      <td>8.351</td>\n",
       "      <td>6.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2.5-flash</th>\n",
       "      <th>Default</th>\n",
       "      <td>0.962</td>\n",
       "      <td>50</td>\n",
       "      <td>52</td>\n",
       "      <td>0.865</td>\n",
       "      <td>7.379</td>\n",
       "      <td>23.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-5-sonnet-20240620</th>\n",
       "      <th>Default</th>\n",
       "      <td>0.938</td>\n",
       "      <td>45</td>\n",
       "      <td>48</td>\n",
       "      <td>0.854</td>\n",
       "      <td>8.230</td>\n",
       "      <td>5.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">claude-3-opus-20240229</th>\n",
       "      <th>Default</th>\n",
       "      <td>0.731</td>\n",
       "      <td>38</td>\n",
       "      <td>52</td>\n",
       "      <td>0.858</td>\n",
       "      <td>11.208</td>\n",
       "      <td>9.582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>With example</th>\n",
       "      <td>0.673</td>\n",
       "      <td>35</td>\n",
       "      <td>52</td>\n",
       "      <td>0.844</td>\n",
       "      <td>7.782</td>\n",
       "      <td>8.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2.5-pro</th>\n",
       "      <th>Default</th>\n",
       "      <td>0.673</td>\n",
       "      <td>35</td>\n",
       "      <td>52</td>\n",
       "      <td>0.868</td>\n",
       "      <td>7.941</td>\n",
       "      <td>18.603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-5-sonnet-20240620</th>\n",
       "      <th>With example</th>\n",
       "      <td>0.280</td>\n",
       "      <td>14</td>\n",
       "      <td>50</td>\n",
       "      <td>0.840</td>\n",
       "      <td>8.330</td>\n",
       "      <td>5.389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Format Compliance  Passed  Total  \\\n",
       "model_name                 prompt_name                                      \n",
       "gemini-2.5-flash           With example              1.000      52     52   \n",
       "gpt-4o                     Default                   1.000      52     52   \n",
       "gpt-4-turbo                Default                   1.000      52     52   \n",
       "gpt-3.5-turbo              With example              1.000      52     52   \n",
       "                           Default                   1.000      52     52   \n",
       "gemini-2.5-pro             With example              1.000      52     52   \n",
       "gpt-4o                     With example              1.000      52     52   \n",
       "gpt-4-turbo                With example              1.000      52     52   \n",
       "gemini-2.5-flash           Default                   0.962      50     52   \n",
       "claude-3-5-sonnet-20240620 Default                   0.938      45     48   \n",
       "claude-3-opus-20240229     Default                   0.731      38     52   \n",
       "                           With example              0.673      35     52   \n",
       "gemini-2.5-pro             Default                   0.673      35     52   \n",
       "claude-3-5-sonnet-20240620 With example              0.280      14     50   \n",
       "\n",
       "                                         BERTScore F1  Readability  Latency  \n",
       "model_name                 prompt_name                                       \n",
       "gemini-2.5-flash           With example         0.846        5.221   22.364  \n",
       "gpt-4o                     Default              0.856        9.483    4.892  \n",
       "gpt-4-turbo                Default              0.859       10.993    8.416  \n",
       "gpt-3.5-turbo              With example         0.847        7.867    2.518  \n",
       "                           Default              0.853        9.089    2.917  \n",
       "gemini-2.5-pro             With example         0.853        6.146   20.442  \n",
       "gpt-4o                     With example         0.849        7.285    4.693  \n",
       "gpt-4-turbo                With example         0.850        8.351    6.496  \n",
       "gemini-2.5-flash           Default              0.865        7.379   23.045  \n",
       "claude-3-5-sonnet-20240620 Default              0.854        8.230    5.018  \n",
       "claude-3-opus-20240229     Default              0.858       11.208    9.582  \n",
       "                           With example         0.844        7.782    8.094  \n",
       "gemini-2.5-pro             Default              0.868        7.941   18.603  \n",
       "claude-3-5-sonnet-20240620 With example         0.840        8.330    5.389  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT ENGINEERING IMPACT\n",
      "Prompt averages (across all 7 models):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Format Compliance</th>\n",
       "      <th>Passed Count</th>\n",
       "      <th>Total Cases</th>\n",
       "      <th>BERTScore F1</th>\n",
       "      <th>Readability (Grade)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Default</th>\n",
       "      <td>0.900</td>\n",
       "      <td>324</td>\n",
       "      <td>360</td>\n",
       "      <td>0.859</td>\n",
       "      <td>9.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engaging</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "      <td>0.895</td>\n",
       "      <td>10.566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Explain like I'm 5</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "      <td>0.870</td>\n",
       "      <td>2.268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>With example</th>\n",
       "      <td>0.854</td>\n",
       "      <td>309</td>\n",
       "      <td>362</td>\n",
       "      <td>0.847</td>\n",
       "      <td>7.277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Format Compliance  Passed Count  Total Cases  \\\n",
       "prompt_name                                                        \n",
       "Default                         0.900           324          360   \n",
       "Engaging                        0.000             0          362   \n",
       "Explain like I'm 5              0.000             0          362   \n",
       "With example                    0.854           309          362   \n",
       "\n",
       "                    BERTScore F1  Readability (Grade)  \n",
       "prompt_name                                            \n",
       "Default                    0.859                9.200  \n",
       "Engaging                   0.895               10.566  \n",
       "Explain like I'm 5         0.870                2.268  \n",
       "With example               0.847                7.277  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRUCTURED vs UNSTRUCTURED PROMPT COMPARISON:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Format Compliance</th>\n",
       "      <th>Passed Count</th>\n",
       "      <th>Total Cases</th>\n",
       "      <th>BERTScore F1</th>\n",
       "      <th>Readability (Grade)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Structured</th>\n",
       "      <td>0.877</td>\n",
       "      <td>633</td>\n",
       "      <td>722</td>\n",
       "      <td>0.853</td>\n",
       "      <td>8.236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unstructured</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>724</td>\n",
       "      <td>0.882</td>\n",
       "      <td>6.417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Format Compliance  Passed Count  Total Cases  BERTScore F1  \\\n",
       "prompt_type                                                                \n",
       "Structured                0.877           633          722         0.853   \n",
       "Unstructured              0.000             0          724         0.882   \n",
       "\n",
       "              Readability (Grade)  \n",
       "prompt_type                        \n",
       "Structured                  8.236  \n",
       "Unstructured                6.417  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 10 MODEL×PROMPT COMBINATIONS (by format compliance):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Format Compliance</th>\n",
       "      <th>Passed</th>\n",
       "      <th>Total</th>\n",
       "      <th>BERTScore F1</th>\n",
       "      <th>Readability</th>\n",
       "      <th>Latency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gemini-2.5-flash</th>\n",
       "      <th>With example</th>\n",
       "      <td>1.000</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.846</td>\n",
       "      <td>5.221</td>\n",
       "      <td>22.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">gpt-3.5-turbo</th>\n",
       "      <th>With example</th>\n",
       "      <td>1.000</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.847</td>\n",
       "      <td>7.867</td>\n",
       "      <td>2.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Default</th>\n",
       "      <td>1.000</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.853</td>\n",
       "      <td>9.089</td>\n",
       "      <td>2.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2.5-pro</th>\n",
       "      <th>With example</th>\n",
       "      <td>1.000</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.853</td>\n",
       "      <td>6.146</td>\n",
       "      <td>20.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">gpt-4-turbo</th>\n",
       "      <th>Default</th>\n",
       "      <td>1.000</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.859</td>\n",
       "      <td>10.993</td>\n",
       "      <td>8.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>With example</th>\n",
       "      <td>1.000</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.850</td>\n",
       "      <td>8.351</td>\n",
       "      <td>6.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">gpt-4o</th>\n",
       "      <th>With example</th>\n",
       "      <td>1.000</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.849</td>\n",
       "      <td>7.285</td>\n",
       "      <td>4.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Default</th>\n",
       "      <td>1.000</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.856</td>\n",
       "      <td>9.483</td>\n",
       "      <td>4.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2.5-flash</th>\n",
       "      <th>Default</th>\n",
       "      <td>0.962</td>\n",
       "      <td>50</td>\n",
       "      <td>52</td>\n",
       "      <td>0.865</td>\n",
       "      <td>7.379</td>\n",
       "      <td>23.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-5-sonnet-20240620</th>\n",
       "      <th>Default</th>\n",
       "      <td>0.938</td>\n",
       "      <td>45</td>\n",
       "      <td>48</td>\n",
       "      <td>0.854</td>\n",
       "      <td>8.230</td>\n",
       "      <td>5.018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Format Compliance  Passed  Total  \\\n",
       "model_name                 prompt_name                                      \n",
       "gemini-2.5-flash           With example              1.000      52     52   \n",
       "gpt-3.5-turbo              With example              1.000      52     52   \n",
       "                           Default                   1.000      52     52   \n",
       "gemini-2.5-pro             With example              1.000      52     52   \n",
       "gpt-4-turbo                Default                   1.000      52     52   \n",
       "                           With example              1.000      52     52   \n",
       "gpt-4o                     With example              1.000      52     52   \n",
       "                           Default                   1.000      52     52   \n",
       "gemini-2.5-flash           Default                   0.962      50     52   \n",
       "claude-3-5-sonnet-20240620 Default                   0.938      45     48   \n",
       "\n",
       "                                         BERTScore F1  Readability  Latency  \n",
       "model_name                 prompt_name                                       \n",
       "gemini-2.5-flash           With example         0.846        5.221   22.364  \n",
       "gpt-3.5-turbo              With example         0.847        7.867    2.518  \n",
       "                           Default              0.853        9.089    2.917  \n",
       "gemini-2.5-pro             With example         0.853        6.146   20.442  \n",
       "gpt-4-turbo                Default              0.859       10.993    8.416  \n",
       "                           With example         0.850        8.351    6.496  \n",
       "gpt-4o                     With example         0.849        7.285    4.693  \n",
       "                           Default              0.856        9.483    4.892  \n",
       "gemini-2.5-flash           Default              0.865        7.379   23.045  \n",
       "claude-3-5-sonnet-20240620 Default              0.854        8.230    5.018  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOTTOM 5 MODEL×PROMPT COMBINATIONS (structured prompts only):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Format Compliance</th>\n",
       "      <th>Passed</th>\n",
       "      <th>Total</th>\n",
       "      <th>BERTScore F1</th>\n",
       "      <th>Readability</th>\n",
       "      <th>Latency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>claude-3-5-sonnet-20240620</th>\n",
       "      <th>With example</th>\n",
       "      <td>0.280</td>\n",
       "      <td>14</td>\n",
       "      <td>50</td>\n",
       "      <td>0.840</td>\n",
       "      <td>8.330</td>\n",
       "      <td>5.389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-opus-20240229</th>\n",
       "      <th>With example</th>\n",
       "      <td>0.673</td>\n",
       "      <td>35</td>\n",
       "      <td>52</td>\n",
       "      <td>0.844</td>\n",
       "      <td>7.782</td>\n",
       "      <td>8.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2.5-pro</th>\n",
       "      <th>Default</th>\n",
       "      <td>0.673</td>\n",
       "      <td>35</td>\n",
       "      <td>52</td>\n",
       "      <td>0.868</td>\n",
       "      <td>7.941</td>\n",
       "      <td>18.603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-opus-20240229</th>\n",
       "      <th>Default</th>\n",
       "      <td>0.731</td>\n",
       "      <td>38</td>\n",
       "      <td>52</td>\n",
       "      <td>0.858</td>\n",
       "      <td>11.208</td>\n",
       "      <td>9.582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-5-sonnet-20240620</th>\n",
       "      <th>Default</th>\n",
       "      <td>0.938</td>\n",
       "      <td>45</td>\n",
       "      <td>48</td>\n",
       "      <td>0.854</td>\n",
       "      <td>8.230</td>\n",
       "      <td>5.018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Format Compliance  Passed  Total  \\\n",
       "model_name                 prompt_name                                      \n",
       "claude-3-5-sonnet-20240620 With example              0.280      14     50   \n",
       "claude-3-opus-20240229     With example              0.673      35     52   \n",
       "gemini-2.5-pro             Default                   0.673      35     52   \n",
       "claude-3-opus-20240229     Default                   0.731      38     52   \n",
       "claude-3-5-sonnet-20240620 Default                   0.938      45     48   \n",
       "\n",
       "                                         BERTScore F1  Readability  Latency  \n",
       "model_name                 prompt_name                                       \n",
       "claude-3-5-sonnet-20240620 With example         0.840        8.330    5.389  \n",
       "claude-3-opus-20240229     With example         0.844        7.782    8.094  \n",
       "gemini-2.5-pro             Default              0.868        7.941   18.603  \n",
       "claude-3-opus-20240229     Default              0.858       11.208    9.582  \n",
       "claude-3-5-sonnet-20240620 Default              0.854        8.230    5.018  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLAUDE 3.5 SONNET: DEFAULT vs WITH EXAMPLE COMPARISON:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Format Compliance</th>\n",
       "      <th>Passed</th>\n",
       "      <th>Total</th>\n",
       "      <th>BERTScore F1</th>\n",
       "      <th>Readability</th>\n",
       "      <th>Latency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Default</th>\n",
       "      <td>0.938</td>\n",
       "      <td>45</td>\n",
       "      <td>48</td>\n",
       "      <td>0.854</td>\n",
       "      <td>8.23</td>\n",
       "      <td>5.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>With example</th>\n",
       "      <td>0.280</td>\n",
       "      <td>14</td>\n",
       "      <td>50</td>\n",
       "      <td>0.840</td>\n",
       "      <td>8.33</td>\n",
       "      <td>5.389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Format Compliance  Passed  Total  BERTScore F1  Readability  \\\n",
       "prompt_name                                                                 \n",
       "Default                   0.938      45     48         0.854         8.23   \n",
       "With example              0.280      14     50         0.840         8.33   \n",
       "\n",
       "              Latency  \n",
       "prompt_name            \n",
       "Default         5.018  \n",
       "With example    5.389  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Overall model averages (across all 4 prompts):\")\n",
    "model_overall = df_success.groupby('model_name').agg({\n",
    "    'format_pass': 'mean',\n",
    "    'bertscore_f1': 'mean',\n",
    "    'flesch_kincaid_grade': 'mean',\n",
    "    'latency_seconds': 'mean'\n",
    "}).round(3)\n",
    "model_overall.columns = ['Format Compliance', 'BERTScore F1', 'Readability (Grade)', 'Latency (seconds)']\n",
    "display(model_overall)\n",
    "\n",
    "print(\"MODEL PERFORMANCE ON STRUCTURED PROMPTS ONLY (Default + With example):\")\n",
    "df_structured = df_success[df_success['prompt_name'].isin(['Default', 'With example'])]\n",
    "\n",
    "print(\"Structured prompt performance by model:\")\n",
    "structured_by_model = df_structured.groupby('model_name').agg({\n",
    "    'format_pass': ['mean', 'sum', 'count'],\n",
    "    'bertscore_f1': 'mean',\n",
    "    'flesch_kincaid_grade': 'mean',\n",
    "    'latency_seconds': 'mean'\n",
    "}).round(3)\n",
    "structured_by_model.columns = ['Format Compliance', 'Passed Count', 'Total Cases', \n",
    "                                'BERTScore F1', 'Readability (Grade)', 'Latency (seconds)']\n",
    "display(structured_by_model)\n",
    "\n",
    "print(\"DETAILED MODEL×PROMPT BREAKDOWN (structured prompts only):\")\n",
    "structured_detail = df_structured.groupby(['model_name', 'prompt_name']).agg({\n",
    "    'format_pass': ['mean', 'sum', 'count'],\n",
    "    'bertscore_f1': 'mean',\n",
    "    'flesch_kincaid_grade': 'mean',\n",
    "    'latency_seconds': 'mean'\n",
    "}).round(3)\n",
    "structured_detail.columns = ['Format Compliance', 'Passed', 'Total', \n",
    "                              'BERTScore F1', 'Readability', 'Latency']\n",
    "display(structured_detail.sort_values('Format Compliance', ascending=False))\n",
    "\n",
    "print(\"PROMPT ENGINEERING IMPACT\")\n",
    "print(\"Prompt averages (across all 7 models):\")\n",
    "prompt_overall = df_success.groupby('prompt_name').agg({\n",
    "    'format_pass': ['mean', 'sum', 'count'],\n",
    "    'bertscore_f1': 'mean',\n",
    "    'flesch_kincaid_grade': 'mean'\n",
    "}).round(3)\n",
    "prompt_overall.columns = ['Format Compliance', 'Passed Count', 'Total Cases', \n",
    "                          'BERTScore F1', 'Readability (Grade)']\n",
    "display(prompt_overall)\n",
    "\n",
    "print(\"STRUCTURED vs UNSTRUCTURED PROMPT COMPARISON:\")\n",
    "df_success['prompt_type'] = df_success['prompt_name'].apply(\n",
    "    lambda x: 'Structured' if x in ['Default', 'With example'] else 'Unstructured'\n",
    ")\n",
    "prompt_type_comparison = df_success.groupby('prompt_type').agg({\n",
    "    'format_pass': ['mean', 'sum', 'count'],\n",
    "    'bertscore_f1': 'mean',\n",
    "    'flesch_kincaid_grade': 'mean'\n",
    "}).round(3)\n",
    "prompt_type_comparison.columns = ['Format Compliance', 'Passed Count', 'Total Cases',\n",
    "                                   'BERTScore F1', 'Readability (Grade)']\n",
    "display(prompt_type_comparison)\n",
    "\n",
    "print(\"TOP 10 MODEL×PROMPT COMBINATIONS (by format compliance):\")\n",
    "top_combos = df_success.groupby(['model_name', 'prompt_name']).agg({\n",
    "    'format_pass': ['mean', 'sum', 'count'],\n",
    "    'bertscore_f1': 'mean',\n",
    "    'flesch_kincaid_grade': 'mean',\n",
    "    'latency_seconds': 'mean'\n",
    "}).round(3)\n",
    "top_combos.columns = ['Format Compliance', 'Passed', 'Total', \n",
    "                      'BERTScore F1', 'Readability', 'Latency']\n",
    "display(top_combos.sort_values('Format Compliance', ascending=False).head(10))\n",
    "\n",
    "print(\"BOTTOM 5 MODEL×PROMPT COMBINATIONS (structured prompts only):\")\n",
    "bottom_structured = structured_detail.sort_values('Format Compliance', ascending=True).head(5)\n",
    "display(bottom_structured)\n",
    "\n",
    "print(\"CLAUDE 3.5 SONNET: DEFAULT vs WITH EXAMPLE COMPARISON:\")\n",
    "claude_comparison = df_structured[df_structured['model_name'] == 'claude-3-5-sonnet-20240620'].groupby('prompt_name').agg({\n",
    "    'format_pass': ['mean', 'sum', 'count'],\n",
    "    'bertscore_f1': 'mean',\n",
    "    'flesch_kincaid_grade': 'mean',\n",
    "    'latency_seconds': 'mean'\n",
    "}).round(3)\n",
    "claude_comparison.columns = ['Format Compliance', 'Passed', 'Total',\n",
    "                             'BERTScore F1', 'Readability', 'Latency']\n",
    "display(claude_comparison)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "review_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
